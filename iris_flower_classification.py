# -*- coding: utf-8 -*-
"""Iris_Flower_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12tR-5qPdT1NCgUMDfe_1P62WiZcgtrdj
"""

import pandas as pd
import numpy as np

from google.colab import files
uploaded = files.upload()

df=pd.read_csv('Iris.csv')

print(df.info)

print(df.describe())

print(df.columns)
print(df.shape)

print(df.duplicated().sum)

print(df.isnull().sum())

df.drop(['Id'], axis=1, inplace=True)

print(df['Species'].unique())
print(df['Species'].value_counts())

import sklearn
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df['Species'] = le.fit_transform(df['Species'])

df['Species'] = df['Species'].replace(np.nan, 0)
print(df)

x=df.drop(["Species"],axis=1)
y=df["Species"]

print("IP=",x)
print("OT=",y)

from sklearn.model_selection import train_test_split, cross_val_score
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=12)

print("DF",df.shape)
print("x_train",x_train.shape)
print("x_test",x_test.shape)
print("y_train",y_train.shape)
print("y_test",y_test.shape)

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Use pipelines to automatically scale data for models that need it
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": make_pipeline(
        StandardScaler(),
        LogisticRegression(max_iter=1000, solver="lbfgs", random_state=42)
    ),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "SVM": make_pipeline(
        StandardScaler(),
        SVC(kernel="rbf", probability=True, random_state=42)
    ),
}

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

model_performance = {}

for Iri, model in models.items():
    # Cross-validation
    cv_scores = cross_val_score(model, x_train, y_train, cv=5, scoring='accuracy')

    # Train model
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)

    # Accuracy
    acc = accuracy_score(y_test, y_pred)
    model_performance[Iri] = acc

    # Final Report
    print(f"\nModel: {Iri}")
    print(f"Cross-Validation Accuracy: {cv_scores.mean():.4f}")
    print(f"Model Accuracy: {acc:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

# Select Best Model
best_model_name = max(model_performance, key=model_performance.get)
best_model = models[best_model_name]

print(f"\n Best Model: {best_model_name} with Accuracy: {model_performance[best_model_name]*100:.2f}%")

import joblib
with open('best_model.joblib', 'wb') as file:
    joblib.dump(best_model, file)

print("\nModel saved successfully as 'best_model.joblib'")

from google.colab import files

files.download('best_model.joblib')